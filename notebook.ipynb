{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Include libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set pandas preferences for output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set interactive output options\n",
    "# to see all of the output\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from IPython.display import display\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "# press 'o' to hyde cell output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sv/tvszn8qx11ngcrsl6yd8t3c80000gp/T/ipykernel_65407/3483327915.py:3: DtypeWarning: Columns (21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  application = pd.read_csv(parent_dir + 'application_train.csv')\n"
     ]
    }
   ],
   "source": [
    "parent_dir = \"./data/\"\n",
    "\n",
    "application = pd.read_csv(parent_dir + 'application_train.csv')\n",
    "# bureau = pd.read_csv(parent_dir + 'bureau.csv')\n",
    "# credit_card_balance = pd.read_csv(parent_dir + 'credit_card_balance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307511, 122)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_col = 'TARGET'\n",
    "\n",
    "application.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Application Train Summary:\\n\", application.info())\n",
    "# print(\"Bureau Summary:\\n\", bureau.info())\n",
    "# print(\"Credit Card Balance Summary:\\n\", credit_card_balance.info())\n",
    "application.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08781828601345662\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x400 with 0 Axes>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='TARGET'>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Target Distribution')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Default (1) or Not (0)')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Count')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "target_dist = application['TARGET'].value_counts(ascending=True)\n",
    "target_probability = print(target_dist[1] / target_dist[0])\n",
    "plt.figure(figsize=(6, 4))\n",
    "target_dist.plot(kind='bar', color=['blue', 'orange'])\n",
    "plt.title('Target Distribution')\n",
    "plt.xlabel('Default (1) or Not (0)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = application.isnull().sum().sort_values(ascending=False)\n",
    "print(len(application))\n",
    "print(\"Missing Values in Application:\\n\", missing_values[missing_values > 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = application.select_dtypes(include=['float64', 'int64'])\n",
    "# correlations = numeric_columns.corr()['TARGET'].sort_values()\n",
    "# print(\"Correlation with TARGET:\\n\", correlations.tail(10))\n",
    "print(numeric_columns.columns.size)\n",
    "print(numeric_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of categorial features\n",
    "cols = application.columns\n",
    "continuous_features = []\n",
    "for column in cols:\n",
    "    if application[column].nunique() > 100:\n",
    "        continuous_features.append(column)\n",
    "\n",
    "print(continuous_features)\n",
    "print(len(continuous_features))\n",
    "# get list of numeric features\n",
    "# floatFeatures = application.select_dtypes(include='float64').columns\n",
    "\n",
    "# integerFeatures = application.select_dtypes(include='int64').columns\n",
    "\n",
    "# for column in integerFeatures:\n",
    "#     if column in nonFloatTypes: # categorial\n",
    "#         integerFeatures = integerFeatures.delete(integerFeatures.get_loc(column))\n",
    "# print(integerFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Построение бокс - графиков для проверки выбросов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'continuous_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 54\u001b[39m\n\u001b[32m     51\u001b[39m     plt.tight_layout()\n\u001b[32m     52\u001b[39m     plt.show()\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m BoxPlotColumns(application, \u001b[43mcontinuous_features\u001b[49m)\n",
      "\u001b[31mNameError\u001b[39m: name 'continuous_features' is not defined"
     ]
    }
   ],
   "source": [
    "def BoxPlotColumns(data, columns):\n",
    "# Создание подграфиков\n",
    "\tnum_features = len(columns)\n",
    "\tnum_cols = int(np.ceil(np.sqrt(num_features)))\n",
    "\n",
    "\t# num_cols = 10  # Количество колонок в сетке\n",
    "\tnum_rows = int(np.ceil(num_features / num_cols))  # Количество строк\n",
    "\n",
    "\t# Создание подграфиков\n",
    "\tfig, axes = plt.subplots(nrows=num_rows, ncols=num_cols, figsize=(5 * num_cols, 4 * num_rows))\n",
    "\t# fig, axes = plt.subplots(nrows=1, ncols=num_features, figsize=(5 * num_features, 4))\n",
    "\n",
    "\t# Построение boxplot для каждой колонки\n",
    "\tindex = 0\n",
    "\tfor ax_arr in axes:\n",
    "\t\tfor ax, column in zip(ax_arr, columns[index: index + num_rows]):\n",
    "\t\t\tg = sns.boxplot(y=data[column], ax=ax)\n",
    "\t\t\t# var = g.set_xticklabels(g.get_xticklabels(), rotation=90)\n",
    "\t\t\tax.set_title(f'Boxplot for {column}')\n",
    "\t\t\tax.set_ylabel(column)\n",
    "\t\tindex = index + num_rows\n",
    "\n",
    "\t# Показать графики\n",
    "\tplt.tight_layout()\n",
    "\tplt.show()\n",
    " \n",
    " \n",
    "def plot_histograms(application, columns):\n",
    "    # Выбор числовых данных\n",
    "    \n",
    "    # Количество признаков\n",
    "    num_features = len(columns)\n",
    "    num_cols = int(np.ceil(np.sqrt(num_features)))  # Количество колонок в сетке\n",
    "    num_rows = int(np.ceil(num_features / num_cols))  # Количество строк\n",
    "    # Создание подграфиков\n",
    "    fig, axes = plt.subplots(nrows=num_rows, ncols=num_cols, figsize=(5 * num_cols, 4 * num_rows))\n",
    "    # Построение гистограммы для каждой колонки\n",
    "    index = 0\n",
    "    for ax_arr in axes:\n",
    "        for ax, column in zip(ax_arr, columns[index: index + num_rows]):\n",
    "            # Построение гистограммы\n",
    "            sns.histplot(application[column], ax=ax, bins=20, kde=True, color='blue', alpha=0.7)\n",
    "            ax.set_title(f'Histogram for {column}')\n",
    "            ax.set_xlabel(column)\n",
    "            ax.set_ylabel('Frequency')\n",
    "        index = index + num_rows\n",
    "    # Удаление пустых подграфиков, если они есть\n",
    "    for j in range(index, num_rows * num_cols):\n",
    "        fig.delaxes(axes.flatten()[j])\n",
    "    # Показать графики\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "BoxPlotColumns(application, continuous_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предобработка данных (удаление / заполнение пропусков, кодировка категориальных признаков)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['OWN_CAR_AGE', 'EXT_SOURCE_1', 'APARTMENTS_AVG', 'BASEMENTAREA_AVG',\n",
      "       'YEARS_BUILD_AVG', 'COMMONAREA_AVG', 'ELEVATORS_AVG', 'ENTRANCES_AVG',\n",
      "       'FLOORSMIN_AVG', 'LANDAREA_AVG', 'LIVINGAPARTMENTS_AVG',\n",
      "       'LIVINGAREA_AVG', 'NONLIVINGAPARTMENTS_AVG', 'NONLIVINGAREA_AVG',\n",
      "       'APARTMENTS_MODE', 'BASEMENTAREA_MODE', 'YEARS_BUILD_MODE',\n",
      "       'COMMONAREA_MODE', 'ELEVATORS_MODE', 'ENTRANCES_MODE', 'FLOORSMIN_MODE',\n",
      "       'LANDAREA_MODE', 'LIVINGAPARTMENTS_MODE', 'LIVINGAREA_MODE',\n",
      "       'NONLIVINGAPARTMENTS_MODE', 'NONLIVINGAREA_MODE', 'APARTMENTS_MEDI',\n",
      "       'BASEMENTAREA_MEDI', 'YEARS_BUILD_MEDI', 'COMMONAREA_MEDI',\n",
      "       'ELEVATORS_MEDI', 'ENTRANCES_MEDI', 'FLOORSMIN_MEDI', 'LANDAREA_MEDI',\n",
      "       'LIVINGAPARTMENTS_MEDI', 'LIVINGAREA_MEDI', 'NONLIVINGAPARTMENTS_MEDI',\n",
      "       'NONLIVINGAREA_MEDI', 'FONDKAPREMONT_MODE', 'HOUSETYPE_MODE',\n",
      "       'WALLSMATERIAL_MODE'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "## удаляем признаки с числом пропущенных значений больше 50%\n",
    "threshold = 0.5\n",
    "missing_ratio = application.isnull().sum() / len(application)\n",
    "columns_to_drop = missing_ratio[missing_ratio > threshold].index\n",
    "application = application.drop(columns=columns_to_drop, axis=1)\n",
    "print(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# разделяем столбцы на числовые и нечисловые данные\n",
    "numeric_data = application.select_dtypes(include=['float64', 'int64'])\n",
    "non_numeric_data = application.select_dtypes(exclude=['float64', 'int64'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для числовых данных заменяем пропущенные значения на медиану столбца\n",
    "imputer_numeric = SimpleImputer(strategy='median')\n",
    "numeric_data_imputed = pd.DataFrame(imputer_numeric.fit_transform(numeric_data), columns=numeric_data.columns)\n",
    "\n",
    "# заменяет пропущенные значения в нечисловых столбцах на наиболее часто встречаемое\n",
    "imputer_non_numeric = SimpleImputer(strategy='most_frequent')\n",
    "non_numeric_data_imputed = pd.DataFrame(imputer_non_numeric.fit_transform(non_numeric_data), columns=non_numeric_data.columns)\n",
    "\n",
    "application_imputed = pd.concat([numeric_data_imputed, non_numeric_data_imputed], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BoxPlotColumns(numeric_data_imputed, numeric_data.columns)\n",
    "# plot_histograms(numeric_data_imputed, numeric_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для каждого категориального признака сопоставляет колонки\n",
    "# feature_main (values in column) = feature1 (value 1[0, 1]) feature2 (value 2[0 ,1]) ...\n",
    "# может возникнуть проблема с потерей информации при кодировании, смотреть отдельно для каждого признака\n",
    "# использовать для таких признаков более точные кодировки (типа бинари)\n",
    "categorical_columns = application_imputed.select_dtypes(include=['object']).columns\n",
    "application_imputed = pd.get_dummies(application_imputed, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "after_merge_imputer = SimpleImputer(strategy='median')\n",
    "application_final = pd.DataFrame(\n",
    "    after_merge_imputer.fit_transform(application_imputed),\n",
    "    columns=application_imputed.columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diplom_project.models.logistic_reg import *\n",
    "logistic_regression_fit_predict(application_final, 'TARGET', 0.2, threshold=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diplom_project.transformers.numeric import handle_outliers, fill_numeric_missing\n",
    "from diplom_project.transformers.categorial import one_hot_encode_columns, impute_with_mode\n",
    "\n",
    "application_final, _ = handle_outliers(application_final, columns=numeric_data.drop(columns='TARGET').columns, method='iqr', strategy='transform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_outliers_variance(data: pd.Series, threshold):\n",
    "    q1 = data.quantile(0.25)\n",
    "    q3 = data.quantile(0.75)\n",
    "    iqr_range = q3 - q1\n",
    "    lower_bound = q1 - threshold * iqr_range\n",
    "    upper_bound = q3 + threshold * iqr_range\n",
    "    outliers_mask = (data < lower_bound) | (data > upper_bound)\n",
    "    new_series = data[outliers_mask].copy()\n",
    "    return new_series.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "data = application_final[\"EXT_SOURCE_3\"]\n",
    "\n",
    "q1 = data.quantile(0.25)\n",
    "q3 = data.quantile(0.75)\n",
    "iqr_range = q3 - q1\n",
    "lower_bound = q1 - threshold * iqr_range\n",
    "upper_bound = q3 + threshold * iqr_range\n",
    "outliers_mask = (data < lower_bound) | (data > upper_bound)\n",
    "new_series = data[outliers_mask].copy()\n",
    "\n",
    "plt.plot(data=new_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Некоторые методы фильтрации данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pearson Kendall spearman corrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# коэффицент пирсона следует использовать на непрерывных данных\n",
    "\n",
    "correlation_ps = application_final.corr(method = 'pearson') # method = pearson or spearman or kendall\n",
    "# print(correlation[target_col].abs().sort_values(ascending=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_tg_abs_ps =  correlation_ps[target_col].abs()\n",
    "\n",
    "print(\"Mean correlation: \",corr_tg_abs_ps.mean())\n",
    "print(\"quantile 0.25: \",corr_tg_abs_ps.quantile(0.25))\n",
    "print(\"quantile 0.4: \",corr_tg_abs_ps.quantile(0.4))\n",
    "print(\"quantile 0.5: \",corr_tg_abs_ps.quantile(0.5))\n",
    "print(\"quantile 0.6: \",corr_tg_abs_ps.quantile(0.6))\n",
    "print(\"quantile 0.75: \",corr_tg_abs_ps.quantile(0.75))\n",
    "\n",
    "corr_tg_abs_ps.sort_values(ascending=False).head(11)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_tg_abs_ps.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-student linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st \n",
    "# проверка на отбранных колонках\n",
    "\n",
    "# return index of result series\n",
    "def get_columns_percentile(data: pd.Series, percentile :float):\n",
    "    s = data.ge(data.quantile(percentile))\n",
    "    # boolean indexing\n",
    "    return s[s].index\n",
    "\n",
    "# calculates t-value for given features and returns list with elems \n",
    "def get_important_features(data: pd.Series, alpha = 0.05):\n",
    "    n = data.size\n",
    "    df = n - 2\n",
    "    critical_value = st.t.ppf(1 - alpha, df)\n",
    "    t = [abs(r) * np.sqrt(n - 2)*np.sqrt(1 - r*r) for r in data]\n",
    "    new_series = pd.Series(t, index = data.index)\n",
    "    # print(\"critical_value: \", critical_value)\n",
    "    return new_series.ge(critical_value)\n",
    "    # return new_series\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "def custom_predict(X, threshold, model):\n",
    "    probs = model.predict_proba(X) \n",
    "    return (probs[:, 1] > threshold).astype(int)\n",
    "\n",
    "def LinearByStudentImportancy(df, corr = corr_tg_abs_ps, alpha = 0.05, penalty='l2'):\n",
    "    \"\"\"penalty: Literal['l1', 'l2', 'elasticnet'] | None = \"l2\",\"\"\"\n",
    "    \n",
    "    imp_f = get_important_features(corr, alpha=alpha)\n",
    "    \n",
    "    \n",
    "    columns = [i for i in df.columns if i in imp_f[imp_f]]\n",
    "    # print (columns)\n",
    "    \n",
    "    X = df[columns]\n",
    "    y = df['TARGET']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\t# стандартизирует диапазон входных данных\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    model = LogisticRegression(penalty = penalty)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # predictions = model.predict(X_test_scaled)\n",
    "    predictions = custom_predict(X_test_scaled, 0.18, model=model)\n",
    "    # print(predictions)\n",
    "\t# predictions = model.score(X_test_scaled)\n",
    "    y_proba = model.predict_proba(X_test_scaled)[: ,1]\n",
    "    auc = roc_auc_score(y_test, model.predict_proba(X_test_scaled)[: ,1])\n",
    "    print(\"features selected: {0}, alpha: {1}\".format(len(columns), alpha))\n",
    "    print(\"Метрики качества модели:\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, predictions):.4f}\")\n",
    "    print(f\"Precision: {precision_score(y_test, predictions):.4f}\")\n",
    "    print(f\"Recall: {recall_score(y_test, predictions):.4f}\")\n",
    "    print(f\"F1-score: {f1_score(y_test, predictions):.4f}\")\n",
    "    print(f\"ROC-AUC: {roc_auc_score(y_test, y_proba):.4f}\")\n",
    "    print(f\"rmse: {root_mean_squared_error(y_test, y_proba):.4f}\")\n",
    "    print(\"\\nМатрица ошибок:\")\n",
    "    print(\"tn    fn\\ntp     fp:\")\n",
    "    print(confusion_matrix(y_test, predictions))    \n",
    "    print(\"AUC Score:\", auc)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_tg_abs_ps =  correlation_ps[target_col]\n",
    "# print(corr_tg_abs_ps)\n",
    "\n",
    "LinearByStudentImportancy(corr = corr_tg_abs_ps, alpha=0.05)\n",
    "LinearByStudentImportancy(corr = corr_tg_abs_ps, alpha=0.1)\n",
    "LinearByStudentImportancy(corr = corr_tg_abs_ps, alpha=0.2)\n",
    "LinearByStudentImportancy(corr = corr_tg_abs_ps, alpha=0.3)\n",
    "LinearByStudentImportancy(corr = corr_tg_abs_ps, alpha=0.4)\n",
    "LinearByStudentImportancy(corr = corr_tg_abs_ps, alpha=0.45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### analize pearson correlation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_f = get_important_features(corr_tg_abs_ps, alpha = 0.45)\n",
    "columns = [i for i in application_final.columns if i in imp_f[imp_f]]\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "\n",
    "normal = 0\n",
    "\n",
    "for col in columns:\n",
    "    res = st.normaltest(application_final[col])\n",
    "    alpha = 0.05\n",
    "    print(res.pvalue, col, len(application_final[col].unique()))\n",
    "    if res.pvalue > alpha:\n",
    "        normal+=1\n",
    "\t\n",
    "print(\"Нормально распределенных признаков: {0}\".format(normal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# plot_histograms(application_final, columns)\n",
    "# BoxPlotColumns(application_final, columns=columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spearman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_sm = application_final.corr(method = 'spearman') # method = pearson or spearman or kendall\n",
    "print(correlation_sm[target_col].abs().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_tg_abs_sm =  correlation_sm[target_col]\n",
    "# corr_tg_abs = correlation.abs()\n",
    "# corr_tg_abs_ps =  correlation_ps[target_col].abs().sort_values(ascending=False)\n",
    "\n",
    "get_important_features(corr_tg_abs_sm, alpha=0.45)\n",
    "\n",
    "LinearByStudentImportancy(corr = corr_tg_abs_sm, alpha=0.05)\n",
    "LinearByStudentImportancy(corr = corr_tg_abs_sm, alpha=0.1)\n",
    "LinearByStudentImportancy(corr = corr_tg_abs_sm, alpha=0.2)\n",
    "LinearByStudentImportancy(corr = corr_tg_abs_sm, alpha=0.3)\n",
    "LinearByStudentImportancy(corr = corr_tg_abs_sm, alpha=0.4)\n",
    "LinearByStudentImportancy(corr = corr_tg_abs_sm, alpha=0.45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_tg_abs.sort_values(ascending=False)\n",
    "# name_education_type\n",
    "# количество признаков, точность\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сравнение Пирсона и Спирмена"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_sm = get_important_features(corr_tg_abs_sm, alpha=0.45)\n",
    "ft_ps = get_important_features(corr_tg_abs_ps, alpha=0.3)\n",
    "\n",
    "ft_sm = [i for i in application_final.columns if i in ft_sm[ft_sm]]\n",
    "ft_ps = [i for i in application_final.columns if i in ft_ps[ft_ps]]\n",
    "\n",
    "\n",
    "# list(ft_sm)\n",
    "sm_ps = [feature for feature in ft_sm if feature not in ft_ps]\n",
    "ps_sm = [feature for feature in ft_ps if feature not in ft_sm]\n",
    "print(sm_ps)\n",
    "print(ps_sm)\n",
    "application_final[ps_sm].hist(figsize=(6, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### linear all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = application_final.drop(columns= ['SK_ID_CURR', 'TARGET'])\n",
    "y = application_final['TARGET']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\t# стандартизирует диапазон входных данных\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = LogisticRegression(max_iter=1000, solver='newton-cg')\n",
    "model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "predictions = model.predict(X_test_scaled)\n",
    "print(predictions)\n",
    "\t# predictions = model.score(X_test_scaled)\n",
    "auc = roc_auc_score(y_test, predictions)\n",
    "print(\"features selected: {0}\".format(len(application_final.columns)))\n",
    "print(\"AUC Score:\", auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "# Предполагаем, что application_final, target_col и другие переменные уже определены\n",
    "X = application_final.drop(columns=target_col)\n",
    "y = application_final[target_col]\n",
    "mi = mutual_info_classif(X, y, discrete_features=True)\n",
    "# Создаем список кортежей (значение взаимной информации, имя колонки)\n",
    "mi_names = list(zip(mi, application_final.columns))\n",
    "# Сортируем список по значениям взаимной информации в порядке убывания\n",
    "mi_names.sort(key=lambda x: x[0], reverse=True)\n",
    "# Выводим отсортированный список\n",
    "for score, name in mi_names:\n",
    "    print(f'Column: {name}, MI: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFE жадный алгоритм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "n_features_to_select = 1\n",
    "application_final = (rd.data[rd.roles['Numeric'] + rd.roles['Categorial'] + ['TARGET']]).copy()\n",
    "\n",
    "X = application_final.drop(columns=['TARGET'], errors='ignore')\n",
    "y = application_final['TARGET']\n",
    "# X = application_final\n",
    "# y = rd.data['TARGET']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "regressor = LogisticRegression()\n",
    "\n",
    "#===========================================================================\n",
    "# perform a scikit-learn Recursive Feature Elimination (RFE)\n",
    "#===========================================================================\n",
    "from sklearn.feature_selection import RFE\n",
    "# here we want only one final feature, we do this to produce a ranking\n",
    "n_features_to_select = 1\n",
    "rfe = RFE(regressor, n_features_to_select=n_features_to_select)\n",
    "rfe.fit(X_train_scaled, y_train)\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "features = X_train.columns.to_list()\n",
    "for x, y in (sorted(zip(rfe.ranking_ , features), key=itemgetter(0))):\n",
    "    print(x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(list(zip(rfe.ranking_, features)), key=itemgetter(0)))\n",
    "rfe_features_sorted = [item[1] for item in sorted(list(zip(rfe.ranking_, features)), key=itemgetter(0))]\n",
    "print(rfe_features_sorted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "def custom_predict(X, threshold):\n",
    "    probs = model.predict_proba(X) \n",
    "    return (probs[:, 1] > threshold).astype(int)\n",
    "\n",
    "number_of_features = 89\n",
    "X = application_final[rfe_features_sorted[:number_of_features]]\n",
    "y = application_final['TARGET']\n",
    "# y = rd.data['TARGET']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\t# стандартизирует диапазон входных данных\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# стандартизирует диапазон входных данных\n",
    "# cols_to_scale = []\n",
    "# for col in rd.roles['Numeric']:\n",
    "#     if col in rfe_features_sorted[:number_of_features]:\n",
    "#         cols_to_scale.append(col)\n",
    "\n",
    "# preprocessor = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         ('num', StandardScaler(), cols_to_scale),\n",
    "#         ('passthrough', 'passthrough', [col for col in X.columns if col not in cols_to_scale])\n",
    "#     ])\n",
    "\n",
    "# # Применяем трансформацию\n",
    "# X_train_scaled = preprocessor.fit_transform(X_train)\n",
    "# X_test_scaled = preprocessor.transform(X_test)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "# threshold_sigmoid = 0.5\n",
    "# lambda_sigmoid =  lambda x: 1 if x > 0.1 else 0\n",
    "predictions = custom_predict(X=X_test_scaled, threshold=0.18)\n",
    "vc = pd.Series(predictions).value_counts()\n",
    "# print(vc[1] / vc[0])\n",
    "# predictions_sigmoid = [lambda_sigmoid(x) for x in predictions]\n",
    "# print([lambda_sigmoid(x) for x in predictions])\n",
    "\t# predictions = model.score(X_test_scaled)\n",
    "# print(accuracy_score(y_test, predictions))\n",
    "auc = roc_auc_score(y_test, model.predict_proba(X_test_scaled)[:, 1])\n",
    "print(\"features selected: {0}\".format(len(X.columns)))\n",
    "print(\"AUC Score:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "# TN, FP\n",
    "# FN, TP\n",
    "print(cm)\n",
    "print((cm[1][1]) / (cm[1][1] + cm[1][0]))\n",
    "print(len(y_test), len(predictions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X=X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_22_rfe = rfe_features_sorted[:22]\n",
    "list_f = [feature for feature in first_22_rfe if feature not in ft_ps]\n",
    "list_f\n",
    "application_final[list_f].hist(figsize=(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X = application_final.drop(columns=['TARGET', 'SK_ID_CURR'])\n",
    "y = application_final['TARGET']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# стандартизирует диапазон входных данных\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = RandomForestClassifier(max_depth=10, min_samples_split=2, min_samples_leaf=2, random_state=42, n_estimators=300)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "predictions = model.predict_proba(X_test_scaled)[:, 1]\n",
    "auc = roc_auc_score(y_test, predictions)\n",
    "print(\"AUC Score:\", auc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from random import randint\n",
    "param_dist = {\n",
    "    'max_depth': [2, 4, 8, 16],\n",
    "    'min_samples_split': [2, 4, 8, 16],\n",
    "    'min_samples_leaf': [2, 4, 8, 16],\n",
    "    'n_estimators': [100, 200, 300 ,500]\n",
    "}\n",
    "dtree_reg = RandomForestClassifier(random_state=42)\n",
    "random_search = RandomizedSearchCV(dtree_reg, param_distributions=param_dist, \n",
    "                                   n_iter=64, cv=5, random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "best_params_random = random_search.best_params_\n",
    "best_score_random = random_search.best_score_\n",
    "\n",
    "print(f\"Best Parameters (Random Search): {best_params_random}\")\n",
    "print(f\"Best Score (Random Search): {best_score_random}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(y_test, model.predict_proba(X_test_scaled)[:, 1])\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'Random Forest (AUC = {auc:.3f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.title('ROC Curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "importances = model.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in model.estimators_], axis=0)\n",
    "\n",
    "\n",
    "\n",
    "forest_importances = pd.Series(importances, index=X_train.columns.values)\n",
    "\n",
    "# plot_data = forest_importances.sort_values(ascending=True).tail(15)\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# plot_data.plot.bar(ax=ax)\n",
    "# ax.set_title(\"Feature importances using MDI\")\n",
    "# ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "# fig.tight_layout(\n",
    "forest_importances.sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_n = 70\n",
    "\n",
    "cols_fst = forest_importances[:features_n].index.values\n",
    "cols_rfe = rfe_features_sorted[:features_n]\n",
    "# print(\"fst: \",cols_fst)\n",
    "\n",
    "# list(ft_sm)\n",
    "fst_rfe = [feature for feature in cols_fst if feature not in cols_rfe]\n",
    "# print(\"rfe: \",cols_rfe)\n",
    "# rfe_fst = [feature for feature in ft_ps if feature not in ft_sm]\n",
    "fst_rfe\n",
    "print([feature1 for feature1, feature2 in zip(cols_fst, cols_rfe) if feature1 != feature2])\n",
    "# # print(sm_ps)\n",
    "# # print(ps_sm)\n",
    "# application_final[fst_rfe].hist(figsize=(6, 6))\n",
    "cols_fst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desicion tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "# columns_dt = application_final[rfe_features_sorted[:30]]\n",
    "columns_dt = application_final.drop(columns=['TARGET', 'SK_ID_CURR']).columns\n",
    "X = application_final[columns_dt]\n",
    "\n",
    "\n",
    "y = application_final['TARGET']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# стандартизирует диапазон входных данных\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = DecisionTreeClassifier(max_depth=7, min_samples_split=2, min_samples_leaf=2, random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "predictions = model.predict_proba(X_test_scaled)[:, 1]\n",
    "auc = roc_auc_score(y_test, predictions)\n",
    "print(\"AUC Score:\", auc)\n",
    "# plot_tree(decision_tree=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from random import randint\n",
    "param_dist = {\n",
    "    'max_depth': [2, 4, 8, 16],\n",
    "    'min_samples_split': [2, 4, 8, 16],\n",
    "    'min_samples_leaf': [2, 4, 8, 16]\n",
    "}\n",
    "dtree_reg = DecisionTreeClassifier(random_state=42)\n",
    "random_search = RandomizedSearchCV(dtree_reg, param_distributions=param_dist, \n",
    "                                   n_iter=64, cv=5, random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "best_params_random = random_search.best_params_\n",
    "best_score_random = random_search.best_score_\n",
    "\n",
    "print(f\"Best Parameters (Random Search): {best_params_random}\")\n",
    "print(f\"Best Score (Random Search): {best_score_random}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feat_importances = pd.DataFrame(model.feature_importances_,  index=columns_dt, columns=[\"Importance\"])\n",
    "feat_importances.sort_values(by='Importance', ascending=False, inplace=True)\n",
    "# feat_importances.plot(kind='bar', figsize=(8,6))\n",
    "feat_importances[:89]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# new res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'iqr'\n",
    "if method == 'zscore':\n",
    "    threshold = 3\n",
    "if method == 'iqr':\n",
    "    threshold = 1.5\n",
    "strategy = 'transform'\n",
    "\n",
    "outliers_percentage_threshold = 0.15\n",
    "impute = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'reader'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mreader\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mreader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Reader\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdiplom_project\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtransformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnumeric\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m handle_outliers, fill_numeric_missing\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdiplom_project\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtransformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcategorial\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'reader'"
     ]
    }
   ],
   "source": [
    "from diplom_project.reader.reader import Reader\n",
    "from diplom_project.transformers.numeric import handle_outliers, fill_numeric_missing\n",
    "from diplom_project.transformers.categorial import *\n",
    "from scipy.stats import zscore, iqr\n",
    "from diplom_project.reader.roles import DropRole\n",
    "\n",
    "rd = Reader(application, target_col='TARGET', id_col='SK_ID_CURR', max_constant_rate=0.995, max_nan_rate=0.45)\n",
    "print(f\"features dropped: {len(rd._get_features_role(DropRole()))}\")\n",
    "print(\"dropped features: \",rd._get_features_role(DropRole()))\n",
    "roles = rd.roles\n",
    "# print(roles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"features dropped: {len(rd._get_features_role(DropRole()))}\")\n",
    "print(\"dropped features: \",rd._get_features_role(DropRole()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# method can be zscore or iqr\n",
    "def count_light_extremal_outliers_ratio(data: pd.DataFrame, col, method = 'zscore'):\n",
    "    if method == 'zscore':\n",
    "        z_scores = zscore(data[col])\n",
    "        threshold_light = 3\n",
    "        threshold_extreme = 3.5\n",
    "        outliers_light_n = len(z_scores[(np.abs(z_scores) < threshold_extreme) & (np.abs(z_scores) > threshold_light)])\n",
    "        outliers_extreme_n = len(z_scores[(np.abs(z_scores) > threshold_extreme)])\n",
    "        if outliers_extreme_n == 0:\n",
    "            ratio = 1.5\n",
    "        else:\n",
    "            ratio = outliers_light_n / outliers_extreme_n\n",
    "    elif method == 'iqr':\n",
    "        q1 = data[col].quantile(0.25)\n",
    "        q3 = data[col].quantile(0.75)\n",
    "        iqr_range = q3 - q1\n",
    "        \n",
    "        lower_bound_light = q1 - threshold * iqr_range\n",
    "        upper_bound_light = q3 + 2* threshold * iqr_range\n",
    "        \n",
    "        lower_bound_extreme = q1 - threshold * iqr_range\n",
    "        upper_bound_extreme = q3 + 2*threshold * iqr_range\n",
    "        \n",
    "        outliers_light_mask = data[col].mask(data[col] > lower_bound_extreme and data[col] < lower_bound_light) | (data[col] > upper_bound_light and data[col] < upper_bound_extreme)\n",
    "        outliers_extreme_mask = data[col].mask((data[col] < lower_bound_extreme) | (data[col] > upper_bound_extreme))\n",
    "        \n",
    "        ratio = data[outliers_light_mask] / data[outliers_extreme_mask]\n",
    "    return ratio\n",
    "\n",
    "outliers_stat = {}\n",
    "\n",
    "\n",
    "    \n",
    "\t\n",
    "rd.data = impute_with_mode(df=rd.data, columns=roles['Numeric'], strategy='median')\n",
    "\n",
    "rd.data = impute_with_mode(df=rd.data, columns=roles['Categorial'], strategy='most_frequent')\n",
    "rd.guess_roles()\n",
    "rd.data = one_hot_encode_columns(df=rd.data, columns_to_encode=roles['Categorial'])\n",
    "\n",
    "res = {'transform': [], 'impute': [], 'clip': []}\n",
    "for col in roles[\"Numeric\"]:\n",
    "\n",
    "    outliers_mask = np.zeros(len(rd.data), dtype=bool)\n",
    "    \n",
    "    if method == 'iqr':\n",
    "        q1 = rd.data[col].quantile(0.25)\n",
    "        q3 = rd.data[col].quantile(0.75)\n",
    "        iqr_range = q3 - q1\n",
    "        lower_bound = q1 - threshold * iqr_range\n",
    "        upper_bound = q3 + threshold * iqr_range\n",
    "        outliers_mask = (rd.data[col] < lower_bound) | (rd.data[col] > upper_bound)\n",
    "    else:\n",
    "        z_scores = zscore(rd.data[col])\n",
    "        outliers_mask = np.abs(z_scores) > threshold\n",
    "        \n",
    "    # Считаем количество выбросов в колонке\n",
    "    outliers_count = outliers_mask.sum()\n",
    "    # print(f\"{col}:  {outliers_count}\")\n",
    "\t# Считаем общее количество значений в колонке\n",
    "    total_count = len(rd.data)\n",
    "\t# Вычисляем процент выбросов\n",
    "    outliers_percentage = float(outliers_count) / total_count\n",
    "    outliers_stat[col] = outliers_percentage\n",
    "    \n",
    "    \n",
    "    if outliers_percentage > outliers_percentage_threshold:\n",
    "        strategy = 'transform'\n",
    "    else:\n",
    "        if impute:\n",
    "            strategy = 'impute'\n",
    "        else:\n",
    "            strategy = 'clip'\n",
    "    res[strategy].append(col)\n",
    "\n",
    "# rd.data['DAYS_EMPLOYED'] = rd.data['DAYS_EMPLOYED'].abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'clip' - заменяет на граничные значения\n",
    "# 'impute' - заменяет на медиану/среднее\n",
    "# 'transform' - применяет логарифмическое преобразование\n",
    "rd.data, _ = handle_outliers(data=rd.data, columns=roles['Numeric'], method=method, strategy='impute', threshold=threshold)\n",
    "# for key in res.keys():\n",
    "# \trd.data, _ = handle_outliers(data=rd.data, columns=res[key], method=method, strategy=key, threshold=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd.guess_roles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diplom_project.models.logistic_reg import *\n",
    "# print(rd.data.select_dtypes(include='object').columns)\n",
    "\n",
    "_, coefs = logistic_regression_fit_predict_coefs(rd.data[rd.roles['Numeric'] + rd.roles['Categorial'] + ['TARGET']], target_column=rd.target_col, return_model=True,threshold=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_outliers_variance(data: pd.Series, threshold):\n",
    "    q1 = data.quantile(0.25)\n",
    "    q3 = data.quantile(0.75)\n",
    "    iqr_range = q3 - q1\n",
    "    lower_bound = q1 - threshold * iqr_range\n",
    "    upper_bound = q3 + threshold * iqr_range\n",
    "    outliers_mask = (rd.data[col] < lower_bound) | (rd.data[col] > upper_bound)\n",
    "    new_series = data[outliers_mask].copy()\n",
    "    return new_series.var()\n",
    "\n",
    "coefs_numeric = [elem for elem in coefs if elem[0] in rd.roles[\"Numeric\"]]\n",
    "print(coefs_numeric)\n",
    "# cols_to_info = [\"AMT_INCOME_TOTAL\",\"AMT_CREDIT\",\"AMT_ANNUITY\",\"AMT_GOODS_PRICE\",\"REGION_POPULATION_RELATIVE\"\t,\"DAYS_EMPLOYED\"\t\t,\"CNT_FAM_MEMBERS\",\"EXT_SOURCE_3\"]\n",
    "cols_to_info = [elem[0] for elem in coefs if elem[0] in rd.roles[\"Numeric\"]]\n",
    "cols_variance = [calculate_outliers_variance(rd.data[col], threshold) for col in cols_to_info]\n",
    "\n",
    "percents = []\n",
    "for col in cols_to_info:\n",
    "    percents.append(outliers_stat[col])\n",
    "    \n",
    "data_outl = pd.DataFrame(data = [[e[1] for e in coefs_numeric if e[0] in cols_to_info], percents, cols_variance], columns= cols_to_info, index = [\"coef\", \"outliers_percent\", \"var\"])\n",
    "data_outl.to_csv(path_or_buf=\"/Users/Stas/source/diplom/diplom_project/clip.csv\", float_format='%.3f')\n",
    "print(data_outl)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## other shit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'AMT_CREDIT'\n",
    "plt.boxplot(rd.data['DAYS_EMPLOYED'])\n",
    "# plt.boxplot(rd.data[col])\n",
    "\n",
    "# rd.data['DAYS_EMPLOYED'].value_counts(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diplom_project.ml_selectors.rfe import *\n",
    "rd.guess_roles()\n",
    "df_rd = (rd.data[rd.roles['Numeric'] + rd.roles['Categorial'] + ['TARGET']])\n",
    "estimator = LogisticRegression(random_state=42, max_iter=150)\n",
    "rank_feature = rank_features_with_rfe(df_rd, target_column=rd.target_col, estimator=estimator)\n",
    "\n",
    "features= [item[1] for item in rank_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diplom_project.models.logistic_reg import *\n",
    "\n",
    "model = logistic_regression_fit_predict(rd.data[features + [target_col]], target_column=rd.target_col, return_model=True, threshold=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e1, e2 in zip(model.coef_[0], df_rd.columns):\n",
    "    if e2 in roles['Numeric']:\n",
    "    \tprint(e1, e2, outliers_stat[e2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(len(rd.roles['Numeric'] + rd.roles['Categorial']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = rd.data[rd.roles['Numeric'] + rd.roles['Categorial']]\n",
    "y = rd.data[target_col]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        # стандартизирует диапазон входных данных\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diplom_project.models.random_forest import *\n",
    "X = rd.data[rd.roles['Numeric'] + rd.roles['Categorial']]\n",
    "y = rd.data[target_col]\n",
    "optimize_random_forest(X=X, y=y,scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X = rd.data[rd.roles['Numeric'] + rd.roles['Categorial']]\n",
    "y = rd.data[target_col]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# стандартизирует диапазон входных данных\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = RandomForestClassifier(max_depth=14, min_samples_split=3, min_samples_leaf=4, random_state=42, n_estimators=600, class_weight='balanced')\n",
    "model.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "predictions = model.predict(X_test_scaled)\n",
    "predic_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test, predictions):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, predictions):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, predictions):.4f}\")\n",
    "print(f\"F1-score: {f1_score(y_test, predictions):.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc_score(y_test, predic_proba):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = np.std([tree.feature_importances_ for tree in model.estimators_], axis=0)\n",
    "\n",
    "# X = rd.data[rd.roles['Numeric'] + rd.roles['Categorial']]\n",
    "# y = rd.data[target_col]\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "forest_importances = pd.Series(model.feature_importances_, index=X_train.columns.values)\n",
    "\n",
    "forest_importances.sort_values(ascending=False)\n",
    "new_cols = forest_importances[:61].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "X = rd.data[forest_importances[:70].index]\n",
    "y = rd.data[target_col]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# стандартизирует диапазон входных данных\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = RandomForestClassifier(max_depth=14, min_samples_split=3, min_samples_leaf=4, random_state=42, n_estimators=600)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=skf, scoring='roc_auc')\n",
    "\n",
    "\n",
    "predictions = model.predict_proba(X_test_scaled)[:, 1]\n",
    "auc = roc_auc_score(y_test, predictions)\n",
    "# print(f\"Средняя точность: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Средняя точность: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_ps = rd.data[rd.roles['Numeric'] + rd.roles['Categorial'] + [rd.target_col]].corr(method = 'pearson')\n",
    "corr_tg_abs_ps =  correlation_ps[rd.target_col]\n",
    "# print(corr_tg_abs_ps)\n",
    "\n",
    "LinearByStudentImportancy(corr = corr_tg_abs_ps, alpha=0.05, df = rd.data)\n",
    "LinearByStudentImportancy(corr = corr_tg_abs_ps, alpha=0.1, df = rd.data)\n",
    "LinearByStudentImportancy(corr = corr_tg_abs_ps, alpha=0.2, df = rd.data)\n",
    "LinearByStudentImportancy(corr = corr_tg_abs_ps, alpha=0.3, df = rd.data)\n",
    "LinearByStudentImportancy(corr = corr_tg_abs_ps, alpha=0.4, df = rd.data)\n",
    "LinearByStudentImportancy(corr = corr_tg_abs_ps, alpha=0.45, df = rd.data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
